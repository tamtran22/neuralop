{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from neuralop import Trainer as Trainer_1\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.models import FNO1d\n",
    "from models.fno1d_activation import FNO1d_activation\n",
    "from torch.utils.data import DataLoader\n",
    "from data.tecplot import *\n",
    "from utils.utils import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = objectview({\n",
    "    'model' : FNO1d,\n",
    "    'model_args': {\n",
    "        'n_modes_height' : 128,\n",
    "        'hidden_channels' : 256,\n",
    "        'in_channels' : 15,\n",
    "        'out_channels' : 3,\n",
    "        'n_layers' : 10,\n",
    "        # 'post_activation' : torch.nn.functional.tanh\n",
    "    },\n",
    "    'train_args': {\n",
    "        'device' : torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
    "        'optimizer' : AdamW,\n",
    "        'lr' : 1e-3,\n",
    "        'weight_decay' : 1e-4,\n",
    "        'scheduler' : torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "        'loss' : H1Loss(d=2),\n",
    "        'trainer' : Trainer_1,\n",
    "        'n_epochs' : 5000,\n",
    "    },\n",
    "    'validate_args': {\n",
    "        'device' : torch.device('cpu')\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [\n",
    "    '../data/it01rh_400-500_slice_trachea.dat',\n",
    "    '../data/it01rh_501-600_slice_trachea.dat',\n",
    "    '../data/it01rh_601-700_slice_trachea.dat',\n",
    "    '../data/it01rh_701-800_slice_trachea.dat'\n",
    "]\n",
    "dataset = load_tecplot_to_pt_dataset(\n",
    "    root_dir='../data/',\n",
    "    dataset_name='tecplot_slice',\n",
    "    n_train=300, \n",
    "    n_test=50, \n",
    "    resolution='medium',\n",
    "    batch_size=10,\n",
    "    normalize=True,\n",
    "    file_names=data_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    dataset.train_db, \n",
    "    batch_size=5, \n",
    "    num_workers=0, \n",
    "    pin_memory=False, \n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = args.model(**args.model_args).to(args.train_args['device'])\n",
    "optimizer = args.train_args['optimizer'](\n",
    "    model.parameters(), \n",
    "    lr=args.train_args['lr'], \n",
    "    weight_decay=args.train_args['weight_decay']\n",
    ")\n",
    "if args.train_args['scheduler'] is not None:\n",
    "    scheduler = args.train_args['scheduler'](optimizer, T_max=60)\n",
    "train_loss = args.train_args['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 300 samples\n",
      "Testing on [] samples         on resolutions [].\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 29.19 GiB memory in use. Of the allocated memory 26.50 GiB is allocated by PyTorch, and 2.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m trainer = args.train_args[\u001b[33m'\u001b[39m\u001b[33mtrainer\u001b[39m\u001b[33m'\u001b[39m](\n\u001b[32m      2\u001b[39m     model = model,\n\u001b[32m      3\u001b[39m     n_epochs = args.train_args[\u001b[33m'\u001b[39m\u001b[33mn_epochs\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     verbose = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_every\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../checkpoints/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/training/trainer.py:209\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, train_loader, test_loaders, optimizer, scheduler, regularizer, training_loss, eval_losses, save_every, save_best, save_dir, resume_from_dir)\u001b[39m\n\u001b[32m    205\u001b[39m     sys.stdout.flush()\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.start_epoch, \u001b[38;5;28mself\u001b[39m.n_epochs):\n\u001b[32m    208\u001b[39m     train_err, avg_loss, avg_lasso_loss, epoch_train_time =\\\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m           \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     epoch_metrics = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    211\u001b[39m         train_err=train_err,\n\u001b[32m    212\u001b[39m         avg_loss=avg_loss,\n\u001b[32m    213\u001b[39m         avg_lasso_loss=avg_lasso_loss,\n\u001b[32m    214\u001b[39m         epoch_train_time=epoch_train_time\n\u001b[32m    215\u001b[39m     )\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[38;5;28mself\u001b[39m.eval_interval == \u001b[32m0\u001b[39m:\n\u001b[32m    218\u001b[39m         \u001b[38;5;66;03m# evaluate and gather metrics across each loader in test_loaders\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/training/trainer.py:269\u001b[39m, in \u001b[36mTrainer.train_one_epoch\u001b[39m\u001b[34m(self, epoch, train_loader, training_loss)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28mself\u001b[39m.n_samples = \u001b[32m0\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     loss.backward()\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/training/trainer.py:432\u001b[39m, in \u001b[36mTrainer.train_one_batch\u001b[39m\u001b[34m(self, idx, sample, training_loss)\u001b[39m\n\u001b[32m    430\u001b[39m         out = \u001b[38;5;28mself\u001b[39m.model(**sample)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.epoch == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m idx == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw outputs of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/models/fno.py:378\u001b[39m, in \u001b[36mFNO.forward\u001b[39m\u001b[34m(self, x, output_shape, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.domain_padding.pad(x)\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_layers):\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfno_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.domain_padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    381\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.domain_padding.unpad(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/layers/fno_block.py:277\u001b[39m, in \u001b[36mFNOBlocks.forward\u001b[39m\u001b[34m(self, x, index, output_shape)\u001b[39m\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward_with_preactivation(x, index, output_shape)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_with_postactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/layers/fno_block.py:292\u001b[39m, in \u001b[36mFNOBlocks.forward_with_postactivation\u001b[39m\u001b[34m(self, x, index, output_shape)\u001b[39m\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    290\u001b[39m         x = torch.tanh(x)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m x_fno = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m#self.convs(x, index, output_shape=output_shape)\u001b[39;00m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/neuralop/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/neuraloperator/neuralop/layers/spectral_convolution.py:500\u001b[39m, in \u001b[36mSpectralConv.forward\u001b[39m\u001b[34m(self, x, output_shape)\u001b[39m\n\u001b[32m    498\u001b[39m     x = torch.fft.ifftn(out_fft, s=mode_sizes, dim=fft_dims, norm=\u001b[38;5;28mself\u001b[39m.fft_norm)\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m     x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mirfftn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfft_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfft_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 3.73 GiB. GPU 0 has a total capacity of 31.73 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 29.19 GiB memory in use. Of the allocated memory 26.50 GiB is allocated by PyTorch, and 2.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer = args.train_args['trainer'](\n",
    "    model = model,\n",
    "    n_epochs = args.train_args['n_epochs'],\n",
    "    # wandb_log = True,\n",
    "    device = args.train_args['device'],\n",
    "    verbose = True\n",
    ")\n",
    "trainer.train(\n",
    "    train_loader = loader,\n",
    "    test_loaders = {},\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    regularizer = False,\n",
    "    training_loss = train_loss,\n",
    "    save_every = 1,\n",
    "    save_dir = '../checkpoints/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = args.model(**args.model_args).to(args.validate_args['device'])\n",
    "model.load_state_dict(torch.load('../checkpoints/model_state_dict.pt', weights_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(loader))\n",
    "output = recurrent_formulation(\n",
    "    model,\n",
    "    initial_input=data['x'][0].unsqueeze(0).float().to(device),\n",
    "    n_iteration=20,\n",
    "    n_timesteps=5,\n",
    "    n_variables=3,\n",
    "    device=torch.device('cpu'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.7247e-01, -3.7357e-01, -3.7235e-01,  ..., -3.5627e-01,\n",
       "           -3.6560e-01, -3.5388e-01],\n",
       "          [-3.0546e-01, -3.0540e-01, -3.0621e-01,  ..., -3.5367e-01,\n",
       "           -3.2565e-01, -3.5033e-01],\n",
       "          [ 2.8617e-01,  2.8475e-01,  2.8450e-01,  ...,  2.5220e-01,\n",
       "            2.7044e-01,  2.6692e-01],\n",
       "          ...,\n",
       "          [-1.7741e+04, -1.7614e+04, -1.7490e+04,  ..., -1.8039e+04,\n",
       "           -1.7955e+04, -1.7869e+04],\n",
       "          [-2.7681e+04, -2.7930e+04, -2.8197e+04,  ..., -2.6996e+04,\n",
       "           -2.7209e+04, -2.7440e+04],\n",
       "          [ 3.8863e+05,  3.9121e+05,  3.9378e+05,  ...,  3.8086e+05,\n",
       "            3.8348e+05,  3.8605e+05]],\n",
       "\n",
       "         [[-4.1958e-01, -4.2046e-01, -4.1834e-01,  ..., -5.6951e-01,\n",
       "           -5.3754e-01, -5.5800e-01],\n",
       "          [ 5.2457e-02,  5.2819e-02,  5.1984e-02,  ..., -1.4681e-01,\n",
       "           -1.2975e-01, -1.2771e-01],\n",
       "          [ 2.1355e+00,  2.1343e+00,  2.1346e+00,  ...,  2.0727e+00,\n",
       "            2.0914e+00,  2.0794e+00],\n",
       "          ...,\n",
       "          [ 2.6288e+04,  2.6259e+04,  2.6229e+04,  ...,  2.6491e+04,\n",
       "            2.6406e+04,  2.6324e+04],\n",
       "          [ 2.0178e+05,  2.0170e+05,  2.0165e+05,  ...,  2.0211e+05,\n",
       "            2.0200e+05,  2.0187e+05],\n",
       "          [ 7.5736e+05,  7.5742e+05,  7.5749e+05,  ...,  7.5716e+05,\n",
       "            7.5725e+05,  7.5731e+05]],\n",
       "\n",
       "         [[ 2.5987e-02,  2.5912e-02,  2.5759e-02,  ...,  2.7427e-01,\n",
       "            2.7281e-01,  2.6380e-01],\n",
       "          [-1.2526e-02, -1.0643e-02, -1.2554e-02,  ...,  1.1285e-01,\n",
       "            1.1563e-01,  1.2843e-01],\n",
       "          [ 4.3143e-01,  4.3161e-01,  4.3101e-01,  ...,  5.1416e-01,\n",
       "            5.0332e-01,  5.0087e-01],\n",
       "          ...,\n",
       "          [ 8.9819e+04,  8.9803e+04,  8.9791e+04,  ...,  8.9735e+04,\n",
       "            8.9788e+04,  8.9836e+04],\n",
       "          [ 4.9425e+05,  4.9418e+05,  4.9422e+05,  ...,  4.9478e+05,\n",
       "            4.9457e+05,  4.9438e+05],\n",
       "          [ 1.0007e+06,  1.0014e+06,  1.0020e+06,  ...,  9.9885e+05,\n",
       "            9.9947e+05,  1.0001e+06]]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 78083])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = output[0,2,:10,700].detach().numpy()\n",
    "\n",
    "yy = data['y']\n",
    "print(yy.shape)\n",
    "yy = yy[]\n",
    "plt.plot(y)\n",
    "# plt.plot(yy)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
